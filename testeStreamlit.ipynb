{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssOqoYwO0goQ"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pdfplumber\n",
        "import re\n",
        "import zipfile\n",
        "import tempfile\n",
        "import os\n",
        "from io import BytesIO\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.title(\"üìÇüìë An√°lise de Ementas de Psicologia via ZIP\")\n",
        "\n",
        "# 1) Upload do ZIP\n",
        "uploaded_zip = st.file_uploader(\n",
        "    \"Fa√ßa upload do arquivo ZIP com todos os PDFs de ementas\",\n",
        "    type=[\"zip\"]\n",
        ")\n",
        "\n",
        "if not uploaded_zip:\n",
        "    st.info(\"Aguardando upload do ZIP...\")\n",
        "    st.stop()\n",
        "\n",
        "# 2) Extrai em pasta tempor√°ria\n",
        "with tempfile.TemporaryDirectory() as tmpdir:\n",
        "    z = zipfile.ZipFile(uploaded_zip)\n",
        "    z.extractall(tmpdir)\n",
        "\n",
        "    # 3) Varre todos os PDFs\n",
        "    registros = []\n",
        "    for root, _, files in os.walk(tmpdir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith(\".pdf\"):\n",
        "                path = os.path.join(root, fn)\n",
        "                # extrai texto\n",
        "                texto = \"\"\n",
        "                with pdfplumber.open(path) as pdf:\n",
        "                    for p in pdf.pages:\n",
        "                        txt = p.extract_text() or \"\"\n",
        "                        texto += txt + \"\\n\"\n",
        "                # regex para nome e c√≥digo\n",
        "                m = re.search(r\"UNIDADE CURRICULAR[:\\s]*(.+?)\\s*\\(\\s*(\\d+)\\s*\\)\", texto, re.IGNORECASE|re.DOTALL)\n",
        "                nome = m.group(1).strip() if m else fn\n",
        "                cod  = m.group(2).strip() if m else fn\n",
        "                # regex para conte√∫do program√°tico\n",
        "                m2 = re.search(\n",
        "                    r\"Conte[√∫u]do program[a√°]tico\\s*[:\\-‚Äì]?\\s*(.*?)\\s*(?:\\n\\s*Bibliografia|\\Z)\",\n",
        "                    texto, re.IGNORECASE|re.DOTALL\n",
        "                )\n",
        "                conteudo = m2.group(1).strip() if m2 else \"\"\n",
        "                registros.append({\"COD_EMENTA\": cod,\n",
        "                                  \"NOME UC\": nome,\n",
        "                                  \"CONTEUDO_PROGRAMATICO\": conteudo})\n",
        "    df_ementas = pd.DataFrame(registros)\n",
        "\n",
        "st.success(f\"{len(df_ementas)} ementas carregadas.\")\n",
        "\n",
        "# Bot√£o de preview\n",
        "st.subheader(\"Preview das primeiras ementas\")\n",
        "st.dataframe(df_ementas.head(5))\n",
        "\n",
        "# Carrega ENADE\n",
        "uploaded_enade = st.file_uploader(\n",
        "    \"Fa√ßa upload do Excel de compet√™ncias ENADE\",\n",
        "    type=[\"xlsx\"], key=\"enade\"\n",
        ")\n",
        "if not uploaded_enade:\n",
        "    st.info(\"Envie o arquivo ENADE para prosseguir.\")\n",
        "    st.stop()\n",
        "\n",
        "enade = pd.read_excel(uploaded_enade).dropna(subset=['DESCRI√á√ÉO'])\n",
        "\n",
        "# Explode frases ENADE\n",
        "enade['FRASE_ENADE'] = (enade['DESCRI√á√ÉO']\n",
        "                        .str.replace('\\n',' ')\n",
        "                        .str.split(r'[.;]')).explode('DESCRI√á√ÉO')\n",
        "enade_expl = enade.assign(FRASE_ENADE=lambda df: df['DESCRI√á√ÉO'].str.strip())\n",
        "enade_expl = enade_expl[enade_expl['FRASE_ENADE'].str.len()>5]\n",
        "\n",
        "# Selecione an√°lise\n",
        "analise = st.sidebar.selectbox(\"Escolha a An√°lise\", [\n",
        "    \"t-SNE das UCs\",\n",
        "    \"Matriz de Similaridade ENADE √ó Ementas\",\n",
        "    \"Matriz de Redund√¢ncia\"\n",
        "])\n",
        "\n",
        "# Pr√©-carrega modelo\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "model = load_model()\n",
        "\n",
        "# t-SNE\n",
        "if analise == \"t-SNE das UCs\":\n",
        "    st.header(\"t-SNE das UCs\")\n",
        "    df_group = (df_ementas.groupby(['COD_EMENTA','NOME UC'])['CONTEUDO_PROGRAMATICO']\n",
        "                          .apply(lambda texts: \" \".join(texts)).reset_index())\n",
        "    texts = df_group['CONTEUDO_PROGRAMATICO'].tolist()\n",
        "    emb = model.encode(texts, convert_to_tensor=False)\n",
        "    n = len(texts)\n",
        "    perp = st.slider(\"Perplexity\", 2, max(2,n//3), value=min(30,max(2,n//3)))\n",
        "    tsne = TSNE(n_components=2, random_state=42, perplexity=perp)\n",
        "    coords = tsne.fit_transform(emb)\n",
        "    df_group['X'], df_group['Y'] = coords[:,0], coords[:,1]\n",
        "    fig, ax = st.pyplot() if False else plt.subplots(figsize=(8,6))\n",
        "    labels = df_group['NOME UC'].unique()\n",
        "    cmap = plt.cm.get_cmap('tab20', len(labels))\n",
        "    for i,l in enumerate(labels):\n",
        "        sub = df_group[df_group['NOME UC']==l]\n",
        "        ax.scatter(sub['X'], sub['Y'], label=l, color=cmap(i), s=40, alpha=0.7)\n",
        "    ax.legend(bbox_to_anchor=(1,1)); ax.set_xlabel(\"t-SNE 1\"); ax.set_ylabel(\"t-SNE 2\")\n",
        "    st.pyplot(fig)\n",
        "\n",
        "# Matriz de Similaridade\n",
        "elif analise == \"Matriz de Similaridade ENADE √ó Ementas\":\n",
        "    st.header(\"Similaridade ENADE √ó Ementas\")\n",
        "    # explode ementas\n",
        "    ementa_expl = df_ementas.assign(\n",
        "        FRASE=lambda df: df['CONTEUDO_PROGRAMATICO']\n",
        "            .str.replace('\\n',' ')\n",
        "            .str.split(r'[.;]')\n",
        "    ).explode('FRASE').assign(FRASE=lambda df: df['FRASE'].str.strip())\n",
        "    ementa_expl = ementa_expl[ementa_expl['FRASE'].str.len()>5]\n",
        "    with st.spinner(\"Gerando embeddings‚Ä¶\"):\n",
        "        emb_e = model.encode(ementa_expl['FRASE'].tolist(), convert_to_tensor=True)\n",
        "        emb_n = model.encode(enade_expl['FRASE_ENADE'].tolist(), convert_to_tensor=True)\n",
        "    sim = util.cos_sim(emb_n, emb_e).cpu().numpy()\n",
        "    # coleta max por combina√ß√£o\n",
        "    rec = []\n",
        "    idxs = ementa_expl.groupby('COD_EMENTA').indices\n",
        "    for cod, sidx in idxs.items():\n",
        "        for i,row in enade_expl.iterrows():\n",
        "            subsim = sim[i, sidx]\n",
        "            rec.append({\n",
        "                \"COD_EMENTA\": cod,\n",
        "                \"FRASE_ENADE\": row['FRASE_ENADE'],\n",
        "                \"MAX_SIM\": float(subsim.max())\n",
        "            })\n",
        "    df_sim = pd.DataFrame(rec).pivot(index='COD_EMENTA', columns='FRASE_ENADE', values='MAX_SIM').fillna(0)\n",
        "    st.dataframe(df_sim.style.background_gradient(cmap=\"RdYlGn_r\"))\n",
        "    toexcel = BytesIO(); df_sim.to_excel(toexcel); toexcel.seek(0)\n",
        "    st.download_button(\"‚¨áÔ∏è Baixar Similaridade\", toexcel, \"sim_enade_ementa.xlsx\")\n",
        "\n",
        "# Matriz de Redund√¢ncia\n",
        "else:\n",
        "    st.header(\"Matriz de Redund√¢ncia\")\n",
        "    df_group = (df_ementas.groupby(['COD_EMENTA'])['CONTEUDO_PROGRAMATICO']\n",
        "                         .apply(lambda txts: \" \".join(txts)).reset_index())\n",
        "    emb = model.encode(df_group['CONTEUDO_PROGRAMATICO'].tolist(), convert_to_tensor=True)\n",
        "    sim = util.cos_sim(emb, emb).cpu().numpy()\n",
        "    df_red = pd.DataFrame(sim, index=df_group['COD_EMENTA'], columns=df_group['COD_EMENTA'])\n",
        "    st.dataframe(df_red.style.background_gradient(cmap=\"RdYlGn_r\"))\n",
        "    toexcel = BytesIO(); df_red.to_excel(toexcel); toexcel.seek(0)\n",
        "    st.download_button(\"‚¨áÔ∏è Baixar Redund√¢ncia\", toexcel, \"redundancia_uc.xlsx\")"
      ]
    }
  ]
}